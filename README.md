## Overview
Within this undertaking, I harnessed the power of SparkSQL to uncover pivotal metrics concerning home sales data. By capitalizing on the capabilities of Spark SQL, I executed a myriad of transformations, aggregations, and calculations on the home sales dataset, unearthing invaluable insights and essential metrics. Moreover, I employed Spark to generate temporary views, partition the data, cache, and subsequently uncached a temporary table, all the while ensuring the table's proper uncaching.

## Tools
![SPARK](https://img.shields.io/badge/Spark%20AR-FF5C83?style=for-the-badge&logo=SparkAR&logoColor=white)

## Project Steps
To begin, I imported the necessary PySpark SQL functions for this assignment. Following that, I read the home_sales_revised.csv data into a Spark DataFrame using the appropriate format and file reading functions.
 
- #### Data insights  
   After reviewing the initial DataFrame to understand its contents, I made the temporary table `home_sales` and utilized SQL queries in order to calculate metrics from the data. I used these queries to answer the following questions:

     - What is the average price for a four-bedroom house sold for each year?
     - What is the average price of a home for each year it was built that has three bedrooms and three bathrooms?
     - What is the average price of a home for each year that has three bedrooms, three bathrooms, two floors, and is greater than or equal to 2,000 square feet?
     - What is the "view" rating for homes costing more than or equal to $350,000? I also determined the run time for this query.

- #### Data Storage and Process Optimization  
   With the following steps, I tested the runtimes of cached and uncached data to find if one is suited for faster processing:
  
     - Cache the temporary table view home_sales.
     - With the cached data, I ran a query previously performed and noted the runtime.
     - Partitioned the data by the "date_built" field on the parquet data and created a temporary table view.
     - Lastly, I ran the same query on the uncached data and compared the runtime results.

## Summary
In summary, the analysis showcased the abilities of Spark SQL in processing and analyzing home sales data, which yielded precious insights by efficiently computing the metrics.

## References
The dataset was generated by edX Boot Camps LLC and is intended for educational purposes only. A thank you to Jayplect for the reference of formatting the .Readme file.
